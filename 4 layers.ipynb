{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eb83d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1370\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "img_transform = transform.Compose([transform.ToTensor()   ]) \n",
    "\n",
    "train_set = torchvision.datasets.ImageFolder('/home/jaoks/Desktop/proyecto6IA/dataset/train', transform=transform.ToTensor())\n",
    "val_set = torchvision.datasets.ImageFolder('/home/jaoks/Desktop/proyecto6IA/dataset/val', transform=transform.ToTensor())\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b1d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_resol_train = torch.utils.data.Subset(train_set, range(685))\n",
    "low_resol_train = torch.utils.data.Subset(train_set, range(685, 1370))\n",
    "\n",
    "hd_resol_val = torch.utils.data.Subset(val_set, range(0, 119))\n",
    "low_resol_val = torch.utils.data.Subset(val_set, range(170, 289))\n",
    "\n",
    "hd_resol_test = torch.utils.data.Subset(val_set, range(119, 170))\n",
    "low_resol_test = torch.utils.data.Subset(val_set, range(289, 340))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5237168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_low = torch.utils.data.DataLoader(dataset=low_resol_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_hd = torch.utils.data.DataLoader(dataset=hd_resol_train, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "val_loader_low =  torch.utils.data.DataLoader(dataset=low_resol_val, batch_size=batch_size, shuffle=True)\n",
    "val_loader_hd =  torch.utils.data.DataLoader(dataset=hd_resol_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader_low =  torch.utils.data.DataLoader(dataset=low_resol_test, batch_size=17, shuffle=True)\n",
    "test_loader_hd =  torch.utils.data.DataLoader(dataset=hd_resol_test, batch_size=17, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23af5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALIDA CONV1\n",
      "torch.Size([1, 64, 254, 254])\n",
      "SALIDA POOL\n",
      "torch.Size([1, 64, 127, 127])\n",
      "SALIDA CONV2\n",
      "torch.Size([1, 128, 125, 125])\n",
      "SALIDA POOL\n",
      "torch.Size([1, 128, 62, 62])\n",
      "SALIDA CONV3\n",
      "torch.Size([1, 256, 60, 60])\n",
      "SALIDA POOL\n",
      "torch.Size([1, 256, 30, 30])\n",
      "SALIDA CONV4\n",
      "torch.Size([1, 512, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "pool1 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "pool2 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
    "pool3 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "tempimg, _ = train_set[0]\n",
    "tempimg = tempimg.unsqueeze(0)\n",
    "out1 = F.relu(conv1(tempimg))\n",
    "print(\"SALIDA CONV1\")\n",
    "print(out1.shape)\n",
    "out1p, ind1 = pool1(out1)\n",
    "print(\"SALIDA POOL\")\n",
    "print(out1p.shape)\n",
    "out2 = F.relu(conv2(out1p))\n",
    "print(\"SALIDA CONV2\")\n",
    "print(out2.shape)\n",
    "out2p, ind2=pool2(out2)\n",
    "print(\"SALIDA POOL\")\n",
    "print(out2p.shape)\n",
    "out3 = F.relu(conv3(out2p))\n",
    "print(\"SALIDA CONV3\")\n",
    "print(out3.shape)\n",
    "out3p, ind3=pool3(out3)\n",
    "print(\"SALIDA POOL\")\n",
    "print(out3p.shape)\n",
    "out4 = F.relu(conv4(out3p))\n",
    "print(\"SALIDA CONV4\")\n",
    "print(out4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a703c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT CT1\n",
      "torch.Size([1, 256, 30, 30])\n",
      "OUTPUT UNPOOL\n",
      "torch.Size([1, 256, 30, 30])\n",
      "torch.Size([1, 256, 60, 60])\n",
      "OUTPUT CT2\n",
      "torch.Size([1, 128, 62, 62])\n",
      "OUTPUT UNPOOL\n",
      "torch.Size([1, 128, 62, 62])\n",
      "torch.Size([1, 128, 125, 125])\n",
      "OUTPUT CT3\n",
      "torch.Size([1, 64, 127, 127])\n",
      "OUTPUT UNPOOL\n",
      "torch.Size([1, 64, 127, 127])\n",
      "torch.Size([1, 64, 254, 254])\n",
      "OUTPUT CT4\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "convTran1 = nn.ConvTranspose2d(in_channels=512,out_channels=256, kernel_size=5, stride=1, padding=0)\n",
    "poolT1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "convTran2 = nn.ConvTranspose2d(in_channels=256*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "poolT2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "convTran3 = nn.ConvTranspose2d(in_channels=128*2,out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "poolT3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "convTran4 = nn.ConvTranspose2d(in_channels=64*2,out_channels=3, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "out_1 = F.relu(convTran1(out4))\n",
    "print(\"OUTPUT CT1\")\n",
    "print(out_1.shape)\n",
    "print(\"OUTPUT UNPOOL\")\n",
    "print(ind3.shape)\n",
    "out_1p = poolT1(out_1, ind3)\n",
    "print(out_1p.shape)\n",
    "out_1p = torch.cat([out_1p, out3], 1)\n",
    "print(\"OUTPUT CT2\")\n",
    "out_2 = F.relu(convTran2(out_1p))\n",
    "print(out_2.shape)\n",
    "print(\"OUTPUT UNPOOL\")\n",
    "print(ind2.shape)\n",
    "out_2p = poolT2(out_2, ind2, output_size= out2.size())\n",
    "print(out_2p.shape)\n",
    "out_2p = torch.cat([out_2p, out2], 1)\n",
    "print(\"OUTPUT CT3\")\n",
    "out_3 = F.relu(convTran3(out_2p))\n",
    "print(out_3.shape)\n",
    "print(\"OUTPUT UNPOOL\")\n",
    "print(ind1.shape)\n",
    "out_3p = poolT3(out_3, ind1)\n",
    "print(out_3p.shape)\n",
    "out_3p = torch.cat([out_3p, out1], 1)\n",
    "print(\"OUTPUT CT4\")\n",
    "out_4 = F.relu(convTran4(out_3p))\n",
    "print(out_4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8dee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, return_indices=True)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, return_indices=True)\n",
    "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool3 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, stride=1, padding=0)\n",
    "    self.sig4 = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, image):\n",
    "    out1 = F.relu(self.bn1(self.conv1(image)))\n",
    "    out1p, ind1 = self.pool1(out1)\n",
    "    out2 = F.relu(self.conv2(out1p))\n",
    "    out2p, ind2 = self.pool2(out2)\n",
    "    out3 = F.relu(self.conv3(out2p))\n",
    "    out3p, ind3 = self.pool3(out3)\n",
    "    out4 = self.sig4(self.conv4(out3p))\n",
    "    z = out4\n",
    "    return z, out1, ind1, out2, ind2, out3, ind3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.convTran1 = nn.ConvTranspose2d(in_channels=512,out_channels=256, kernel_size=5, stride=1, padding=0)\n",
    "    self.poolT1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran2 = nn.ConvTranspose2d(in_channels=256*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran3 = nn.ConvTranspose2d(in_channels=128*2,out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran4 = nn.ConvTranspose2d(in_channels=64*2,out_channels=3, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    \n",
    "  def forward(self, latent, out1, ind1, out2, ind2, out3, ind3):\n",
    "    out = F.relu(self.convTran1(latent))\n",
    "    out = self.poolT1(out, ind3)\n",
    "    out = torch.cat([out, out3], 1)\n",
    "    out = F.relu(self.convTran2(out))\n",
    "    out = self.poolT2(out, ind2, output_size= out2.size())\n",
    "    out = torch.cat([out, out2], 1)\n",
    "    out = F.relu(self.convTran3(out))\n",
    "    out = self.poolT3(out, ind1)\n",
    "    out = torch.cat([out, out1], 1)\n",
    "    out = F.relu(self.convTran4(out))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e21b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "   def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "   def forward(self, x):\n",
    "        latent, out1, ind1, out2, ind2, out3, ind3 = self.encoder(x)\n",
    "        x_recon = self.decoder(latent, out1, ind1, out2, ind2, out3, ind3)\n",
    "        return  x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b3d2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, train_loader_hd, val_loader, val_loader_hd, Epochs, loss_fn):\n",
    "    train_loss_avg = []\n",
    "    val_loss_avg = []\n",
    "    for epoch in range(Epochs):\n",
    "        train_loss_avg.append(0)\n",
    "        num_batches = 0\n",
    "        iterator = iter(train_loader_hd)\n",
    "        for image_batch, _ in train_loader:\n",
    "            image_batch = image_batch.to(device)\n",
    "            batch_list = next(iterator)\n",
    "            image_batch_hd = batch_list[0].to(device)\n",
    "            image_batch_recon = model(image_batch)\n",
    "            loss = loss_fn(image_batch_recon, image_batch_hd)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            train_loss_avg[-1] += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        train_loss_avg[-1] /= num_batches\n",
    "        print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, Epochs, train_loss_avg[-1]))\n",
    "        \n",
    "        iterator = iter(val_loader_hd)\n",
    "        val_loss_avg.append(0)\n",
    "        num_batches=0\n",
    "        for image_batch, _ in val_loader:\n",
    "            image_batch = image_batch.to(device)\n",
    "            batch_list = next(iterator)\n",
    "            image_batch_hd = batch_list[0].to(device)\n",
    "            image_batch_recon = model(image_batch)\n",
    "            with torch.no_grad():\n",
    "                loss = loss_fn(image_batch_recon, image_batch_hd)\n",
    "                val_loss_avg[-1] += loss.item()\n",
    "                num_batches += 1\n",
    "        val_loss_avg[-1] /= num_batches\n",
    "        print('Epoch [%d / %d] average reconstruction validation error: %f' % (epoch+1, Epochs, val_loss_avg[-1]))\n",
    "                \n",
    "    return train_loss_avg, val_loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3387376",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 3.81 GiB total capacity; 64.25 MiB already allocated; 48.19 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d9f751054fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mloss_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_hd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_hd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e1c91602189e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, train_loader_hd, val_loader, val_loader_hd, Epochs, loss_fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimage_batch_hd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mimage_batch_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch_hd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-398f7813e42d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mx_recon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ad61d2dcd713>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mout1p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2283\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 3.81 GiB total capacity; 64.25 MiB already allocated; 48.19 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "capacity = 64\n",
    "epochs = 100    \n",
    "learning_rate = 0.001\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=autoencoder.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "\n",
    "loss_result, loss_val = train(autoencoder,train_loader_low, train_loader_hd, val_loader_low, val_loader_hd, epochs, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef40c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, _ in train_loader_low:\n",
    "  image_batch = image_batch.to(device)\n",
    "  image_batch_recon = autoencoder(image_batch)\n",
    "  #Show_imgs(image_batch[0].cpu(),\"\")\n",
    "  #Show_imgs(image_batch_recon[0].cpu(),\"\")\n",
    "  #image_batch[0].cpu() \n",
    "  im = transform.ToPILImage()(image_batch[0]).convert(\"RGB\")  \n",
    "  display(im)\n",
    "  imt = transform.ToPILImage()(image_batch_recon[0]).convert(\"RGB\")\n",
    "  display(imt) \n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033fcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a42463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8842260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82debd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222af74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac531d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43549225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
